{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\\begin{center}\n", "\\begin{huge}\n", "DATA203 Foundational Python (Prof. Maull) / Fall 2024 / HW4\n", "\\end{huge}\n", "\\end{center}\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 30 | Sunday, December 01 | _up to_ 30 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by University or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* Use Pandas for data engineering of AQ data\n", "\n", "* Use Pandas for API data extraction of AQ data\n", "\n", "* Understand background knowledge to understand function implementation\n", "\n", "* Understand data merging and analysis using Pandas\n", "\n", "* Explore data plots of AQ data using Pandas\n", "\n", "## WHAT TO TURN IN\n", "You are being encouraged to turn the assignment in using the provided\n", "Jupyter Notebook.  To do so, make a directory in your Lab environment called\n", "`homework/hw1`.   Put all of your files in that directory.  Then zip or tar that directory,\n", "rename it with your name as the first part of the filename (e.g. `maull_hw1_files.zip`, `maull_hw1_files.tar.gz`), then\n", "download it to your local machine, then upload the `.zip` to Canvas.\n", "\n", "If you do not know how to do this, please ask, or visit one of the many tutorials out there\n", "on the basics of using zip in Linux.  \n", "\n", "If you choose not to use the provided notebook, you will still need to turn in a\n", "`.ipynb` Jupyter Notebook and corresponding files according to the instructions in\n", "this homework.\n", "\n", "\n", "## ASSIGNMENT TASKS\n", "### (25%) Use Pandas for data engineering of AQ data \n", "\n", "In the previous assignment, we learned that the EJ Screen tool\n", "provided a wealth of data that we could use to both visualize\n", "and analyze data from the EPA.\n", "\n", "We also learned that there were other sources of data, \n", "namely data from citizen science sources like Purple Air\n", "and also from historical sources like the Internet Archive.\n", "\n", "In the prior assignment, you obtained a sense of the work\n", "involved in getting this data.  Luckily, this can be\n", "automated with a little effort.\n", "\n", "Instead of having you do that automation, you will\n", "be able to see it in action if you wish.  There are two \n", "notebooks titled `pre_nb001` and `pre_nb002`, which\n", "contain the code to get data from Internet Archive\n", "Common Crawl files, and from Purple Air.  You will\n", "notice the Purple Air data extraction uses a machine\n", "API (application programmer interface) which \n", "makes getting data exceedingly easy in Python\n", "and other languages.  The data from Common Crawl\n", "is not as easy to obtain -- it requires a \n", "bit more complexity by requiring the archive\n", "pages to be parsed from the HTML source.  This\n", "technique is often _required_ when there is no\n", "API, furthermore, since the LDEQ data forecasts\n", "are not archived anywhere, we must rely on what\n", "we can get from the IA/Common Crawl files.\n", "\n", "The fact that these files exist and can be easily\n", "accessed by anyone with a decent Internet \n", "connections is critical and important -- you \n", "can contemplate  the profundity of this \n", "reality.\n", "\n", "**&#167; Task:**  Study the `pre_nb001` and  `pre_nb002` notebooks.\n", "You will not need to do anything with them,\n", "not will you have to run them, but know\n", "that a working data scientist has some \n", "knowledge about how this process works (when\n", "using a tool to perform these tasks), if not\n", "a basic knowledge of how to do it manually when\n", "called to do so.\n", "\n", "\n", "**&#167; Task:**  Please open [`hw4_001_extract_explore_explain.ipynb`](https://github.com/kmhuads/f24_data203/blob/main/hw4/hw4_001_extract_explore_explain.ipynb)\n", "and follow the instructions and answer\n", "the questions _in_ the notebook.\n", "\n", "\n", "\n", "### (25%) Use Pandas for API data extraction of AQ data \n", "\n", "Often once data is extracted from their sources\n", "additional transformation needs to be done,\n", "for example to convert data, average it or\n", "perform other important pre-processing\n", "steps on the data.\n", "\n", "The data is often in multiple files and\n", "needs to be combined for further processing.\n", "\n", "You will learn a bit more about this process\n", "in the task below.\n", "\n", "**&#167; Task:**  Please open [`hw4_002_api_explore_explain.ipynb`](https://github.com/kmhuads/f24_data203/blob/main/hw4/hw4_002_api_explore_explain.ipynb)\n", "and follow the instructions and answer\n", "the questions _in_ the notebook.\n", "\n", "\n", "\n", "### (15%) Understand background knowledge to understand function implementation \n", "\n", "Often you will need to read the conversations of others\n", "to understand how code was implemented (or how to implement\n", "something yourself).\n", "\n", "In this part you will look at another notebook\n", "and understand why some decisions were made in \n", "code that is being included in the existing \n", "base (I already wrote it, so you do no have \n", "to do so).\n", "\n", "**&#167; Task:**  Please open [`hw4_003_transform_explore_explain.ipynb`](https://github.com/kmhuads/f24_data203/blob/main/hw4/hw4_003_transform_explore_explain.ipynb)\n", "and follow the instructions and answer\n", "the questions _in_ the notebook.\n", "\n", "\n", "\n", "### (20%) Understand data merging and analysis using Pandas \n", "\n", "After you have data that you need, the final work that needs to \n", "be done often requires final cutting, labeing and merging, with\n", "the output being your data of interest that you will\n", "analyze, plot, run statistical tests or even build models from\n", "(or get inspiration for building such models).\n", "\n", "**&#167; Task:**  Please open [`hw4_004_merge_explain.ipynb`](https://github.com/kmhuads/f24_data203/blob/main/hw4/hw4_004_merge_explain.ipynb)\n", "and follow the instructions and answer\n", "the questions _in_ the notebook.\n", "  \n", "\n", "\n", "\n", "### (15%) Explore data plots of AQ data using Pandas \n", "\n", "The fun of analysis is in the pretty pictures.\n", "While partially fecetious, the reality is \n", "no one except the data geeks want to see\n", "the numbers -- things come alive and stories\n", "get interesting when data is visualized.\n", "\n", "In this part, you will explore a plot\n", "and answer a simple question about it.\n", "\n", "**&#167; Task:**  Please open [`hw4_005_plot_explain.ipynb`](https://github.com/kmhuads/f24_data203/blob/main/hw4/hw4_005_plot_explain.ipynb)\n", "and follow the instructions and answer\n", "the questions _in_ the notebook.\n", "\n", "\n", "\n"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "toc": {"colors": {"hover_highlight": "#DAA520", "navigate_num": "#000000", "navigate_text": "#333333", "running_highlight": "#FF0000", "selected_highlight": "#FFD700", "sidebar_border": "#EEEEEE", "wrapper_background": "#FFFFFF"}, "moveMenuLeft": true, "nav_menu": {"height": "12px", "width": "252px"}, "navigate_menu": true, "number_sections": false, "sideBar": true, "threshold": "1", "toc_cell": false, "toc_section_display": "block", "toc_window_display": true, "widenNotebook": false}}, "nbformat": 4, "nbformat_minor": 0}